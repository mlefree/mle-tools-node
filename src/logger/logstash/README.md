# Logstash ELK Stack Integration

This folder provides a complete ELK (Elasticsearch, Logstash, Kibana) stack integration for processing and visualizing
logs generated by the mle-tools-node Logger.

## Overview

The ELK stack integration allows you to:

- **Collect** logs from the mle-tools-node Logger using Logstash
- **Store** and index logs in Elasticsearch with automated lifecycle management
- **Visualize** and analyze logs through Kibana dashboards
- **Monitor** application behavior and troubleshoot issues effectively
- **Automate** the entire setup and verification process with `npm run test:elk`

## Quick Start

### Automated Setup (Recommended)

The fastest way to get started is using the automated setup script:

```bash
# From the project root
npm run test:elk
```

This command executes the `elk-setup-and-verify.js` script which provides complete automation for:

1. âœ… **Force Recreate ELK Stack** - Stops and removes existing containers, recreates all services
2. âœ… **Volume Verification** - Checks that mounted volumes (`/app/logs/sample:ro` and `/app/logs/mle-tools:ro`) are
   accessible
3. âœ… **Test Integration** - Runs npm test to generate application logs
4. âœ… **Log Verification** - Confirms logs are properly indexed in Elasticsearch
5. âœ… **Index Pattern Creation** - Automatically creates Kibana index patterns for visualization
6. âœ… **Service Health Monitoring** - Waits for all services to be healthy before proceeding
7. âœ… **Comprehensive Reporting** - Provides detailed progress logs and access information

#### Expected Output

The automated setup provides detailed progress information:

```
[2025-08-10T18:23:05.000Z] [INFO] ðŸš€ Starting ELK Stack Setup and Verification Process...
[2025-08-10T18:23:05.100Z] [INFO] ðŸš€ Starting ELK stack with force recreate...
[2025-08-10T18:23:45.000Z] [INFO] âœ… ELK stack created successfully
[2025-08-10T18:24:15.000Z] [INFO] âœ… Elasticsearch is ready
[2025-08-10T18:24:45.000Z] [INFO] âœ… Kibana is ready
[2025-08-10T18:24:46.000Z] [INFO] âœ… /app/logs/sample:ro volume is mounted and accessible
[2025-08-10T18:24:46.100Z] [INFO] âœ… /app/logs/mle-tools:ro volume is mounted
[2025-08-10T18:25:30.000Z] [INFO] âœ… npm test completed successfully
[2025-08-10T18:25:45.000Z] [INFO] âœ… Found 9 app-logs indices with log entries
[2025-08-10T18:25:46.000Z] [INFO] âœ… Kibana index pattern created successfully
[2025-08-10T18:25:46.100Z] [INFO] ðŸŽ‰ ELK Stack Setup and Verification Complete!
```

### Manual Setup

If you prefer manual control:

```bash
cd src/logger/logstash
docker-compose up -d
```

Then verify services at:

- **Elasticsearch**: http://localhost:9200
- **Kibana**: http://localhost:5601

## Architecture

The setup consists of four main services orchestrated through Docker Compose:

### 1. Elasticsearch (Port 9200)

- **Purpose**: Search and analytics engine for log storage and indexing
- **Version**: 8.12.0
- **Configuration**: Single-node setup with security disabled for development
- **Storage**: Persistent data volume at `./.gen/es_data`
- **Memory**: 512MB heap size (configurable via ES_JAVA_OPTS)

### 2. Kibana (Port 5601)

- **Purpose**: Web interface for log visualization and analysis
- **Version**: 8.12.0
- **Access**: http://localhost:5601
- **Features**: Dashboard creation, log searching, data exploration

### 3. Logstash

- **Purpose**: Log processing pipeline that reads, transforms, and forwards logs
- **Version**: 8.12.0
- **Configuration**: Custom pipeline defined in `logstash.conf`
- **Input**: Monitors log files matching pattern `/app/logs/*/log-*.log`
- **Output**: Sends processed logs to Elasticsearch with dynamic indexing

### 4. ILM Setup (Index Lifecycle Management)

- **Purpose**: Automated log retention and cleanup policies
- **Policy**:
    - Hot phase: Rollover after 50GB or 1 day
    - Delete phase: Remove logs older than 30 days
- **Templates**: Automatic index template application for `app-logs-*` patterns
- **Compliance**: âœ… **FULLY COMPLIANT** with actual Logstash index patterns

## File Structure

```
src/logger/logstash/
â”œâ”€â”€ README.md                    # This comprehensive documentation
â”œâ”€â”€ docker-compose.yml           # ELK stack orchestration
â”œâ”€â”€ logstash.conf               # Logstash pipeline configuration  
â”œâ”€â”€ setup_ilm.sh               # Index Lifecycle Management setup (ILM compliant)
â””â”€â”€ logs_sample/               # Sample log files for testing
    â””â”€â”€ log-2025-08-06-13.log
```

## Setup Instructions

### Prerequisites

- Docker and Docker Compose installed
- At least 2GB RAM available for the stack

### Quick Start

1. **Start the ELK Stack**:
   ```bash
   cd src/logs/logstash
   docker-compose up -d
   ```

2. **Verify Services**:
    - Elasticsearch: http://localhost:9200
    - Kibana: http://localhost:5601

3. **Check Logs**:
   ```bash
   docker-compose logs -f logstash
   ```

### Integration with mle-tools-node Logger

The Logger from mle-tools-node creates daily rotating log files in the format:

```
.logs/log-YYYY-MM-DD-HH.log
```

To integrate with this ELK stack:

1. **Map your logs directory** in docker-compose.yml:
   ```yaml
   volumes:
     - "../../.logs:/app/logs/mle-tools:ro"
   ```

2. **Update logstash.conf** if needed to match your log format and add custom parsing.

3. **Configure Logger** in your application:
   ```typescript
   import { Logger } from 'mle-tools-node';
   
   const logger = new Logger('my-service');
   logger.info('This will be indexed in Elasticsearch');
   ```

## Configuration Details

### Logstash Pipeline (`logstash.conf`)

- **Input**: File input plugin monitoring log files
- **Output**:
    - stdout for debugging (with rubydebug codec)
    - Elasticsearch with dynamic index naming: `app-logs-{service}-{year}.{month}.{day}`

### Index Management

- **Policy Name**: `logs_policy`
- **Retention**: 30 days
- **Rollover**: 50GB or daily
- **Template**: Applied automatically to all `app-logs-*` indices

## Usage Examples

### Viewing Logs in Kibana

1. Access http://localhost:5601
2. Go to "Discover" section
3. Create an index pattern: `app-logs-*`
4. Explore your logs with time-based filtering

### Viewing Logstash Logs

Logstash logs provide insights into the processing pipeline, including startup information, file monitoring status, and
any parsing issues. Here are multiple ways to monitor Logstash:

#### Method 1: In Kibana (Recommended for Analysis)

1. **Access Kibana**: http://localhost:5601
2. **Navigate to Discover**
3. **Create index pattern**: Use `logs-*` to view processed application logs
4. **Filter by service**: Use `service:logstash` or `service:mle-tools` to see logs from specific sources
5. **Monitor processing status**: Look for parsing errors or successful indexing events

#### Method 2: Docker Compose Commands

```bash
# View recent logs (last 50 lines)
docker-compose logs --tail 50 logstash

# Follow logs in real-time
docker-compose logs -f logstash

# View logs with timestamps
docker-compose logs -t logstash

# Filter for errors and warnings
docker-compose logs logstash 2>&1 | grep -i error
docker-compose logs logstash 2>&1 | grep -i warn
```

#### Method 3: Docker Direct Commands

```bash
# View recent logs
docker logs --tail 50 logstash

# Follow logs in real-time
docker logs -f logstash

# View logs since specific time
docker logs --since=10m logstash

# Filter for specific patterns
docker logs logstash 2>&1 | grep "Started Logstash"
docker logs logstash 2>&1 | grep "pipeline"
```

#### Method 4: Log Analysis Commands

```bash
# Check if Logstash is monitoring files
docker logs logstash 2>&1 | grep "Registering"

# Monitor pipeline status
docker logs logstash 2>&1 | grep "Pipeline started"

# Check for processing activity
docker logs logstash 2>&1 | grep -E "(processing|event)"

# View startup configuration
docker logs logstash 2>&1 | head -20
```

#### Common Log Patterns to Monitor

**Normal Startup Indicators:**

- `"Starting Logstash"` - Service initialization
- `"Pipeline started successfully"` - Processing pipeline active
- `"Registering file input"` - File monitoring configured

**Processing Activity:**

- Look for regular activity in stdout output (when `stdout { codec => rubydebug }` is enabled)
- Check for successful Elasticsearch connections

**Warning Patterns (Usually Safe to Ignore):**

- ECS version compatibility warnings
- Monitoring configuration suggestions
- Method redefinition warnings from Ruby gems

**Error Patterns (Require Attention):**

- Connection failures to Elasticsearch
- File permission issues
- Grok parsing failures
- Pipeline configuration errors

### Querying Elasticsearch Directly

```bash
# Get all indices
curl http://localhost:9200/_cat/indices

# Search recent logs
curl http://localhost:9200/app-logs-*/_search?q=level:error

# Get index statistics
curl http://localhost:9200/app-logs-*/_stats
```

### Sample Log Processing

The `logs_sample` directory contains example log files that demonstrate the expected format and processing capabilities.

## ILM Compliance Status

### âœ… FULLY COMPLIANT

The Index Lifecycle Management (ILM) setup has been verified and is **fully compliant** with the actual Logstash index
patterns:

- **Index Pattern Match**: âœ… `app-logs-*` matches Logstash output patterns
- **ILM Policy Applied**: âœ… All app-logs indexes managed by `logs_policy`
- **Template Coverage**: âœ… `app_logs_template` applies to all new app-logs indexes
- **Alias Configuration**: âœ… Rollover alias properly configured as `app-logs`
- **Lifecycle Management**: âœ… 30-day retention, 1-day/50GB rollover active

### Key Fixes Applied

The setup was updated to resolve a critical mismatch:

- **Before**: ILM used pattern `logs-*` but Logstash created `app-logs-*` indexes
- **After**: ILM template updated to `app-logs-*` pattern for full compliance

### Verification Commands

```bash
# Check ILM policy status
curl "http://localhost:9200/_ilm/policy/logs_policy"

# Monitor index sizes and ages  
curl "http://localhost:9200/_cat/indices/app-logs-*?v&s=creation.date"

# Check rollover alias
curl "http://localhost:9200/_cat/aliases/app-logs?v"
```

### Essential Commands

```bash
# Quick start (automated)
npm run test:elk

# Manual ELK startup
cd src/logger/logstash && docker-compose up -d

# Check service status
docker-compose ps

# View logs
docker-compose logs -f logstash

# Stop and cleanup
docker-compose down -v --remove-orphans
```

### Service URLs

- **Elasticsearch**: http://localhost:9200
- **Kibana**: http://localhost:5601
- **Index Pattern**: `app-logs-*`

### Log Index Format

- **Pattern**: `app-logs-{service}-{year}.{month}.{day}`
- **Examples**: `app-logs-mle-tools-2025.08.10`, `app-logs-sample-service-2025.08.10`

### Volume Mounts

- `/app/logs/sample:ro` - Sample log files for testing
- `/app/logs/mle-tools:ro` - Application logs from mle-tools-node Logger

### ILM Policy Settings

- **Policy Name**: `logs_policy`
- **Hot Phase**: Rollover after 50GB or 1 day
- **Delete Phase**: Remove logs after 30 days
- **Template**: `app_logs_template` for `app-logs-*` patterns

### Key Files

- `docker-compose.yml` - ELK stack orchestration
- `logstash.conf` - Log processing pipeline
- `setup_ilm.sh` - Index lifecycle management setup
- `elk-setup-and-verify.js` - Automated setup and verification script
- `logs_sample/` - Sample log files

## Troubleshooting

### Common Issues

1. **Elasticsearch not starting**: Check available memory (requires ~1GB)
2. **Logstash not processing files**: Verify file permissions and paths
3. **Kibana connection refused**: Wait for Elasticsearch health check to pass
4. **Kibana warning: "index_not_found_exception: no such index [.kibana]"**:
    - This is **normal behavior** during Kibana's first startup
    - Kibana automatically creates its system indices (.kibana, .kibana_task_manager, etc.) on first run
    - The warning will disappear once initialization completes (typically 1-2 minutes)
    - No action required - just wait for the initialization to finish
5. **Disk watermark exceeded errors**:
    - **Symptoms**: Cluster status "red", unassigned shards, "flood stage disk watermark exceeded" warnings
    - **Cause**: Host system has low disk space (typically >95% used)
    - **Solution**: Configure more lenient watermark thresholds for development:
      ```bash
      curl -X PUT "http://localhost:9200/_cluster/settings" -H 'Content-Type: application/json' -d '{
        "persistent": {
          "cluster.routing.allocation.disk.watermark.low": "97%",
          "cluster.routing.allocation.disk.watermark.high": "98%",
          "cluster.routing.allocation.disk.watermark.flood_stage": "99%"
        }
      }'
      ```
    - **Prevention**: Monitor disk usage with `df -h` and clean up unnecessary files
    - **Note**: These settings are configured by default in the docker-compose.yml for development use

### Useful Commands

```bash
# Check service status
docker-compose ps

# View service logs
docker-compose logs elasticsearch
docker-compose logs logstash
docker-compose logs kibana

# Restart services
docker-compose restart

# Clean up
docker-compose down -v
```

## Development and Testing

For development purposes, the stack includes sample logs and is configured for easy local testing. The setup
automatically creates the necessary indices and applies lifecycle policies on startup.

The integration is designed to work seamlessly with the mle-tools-node logging system, providing comprehensive log
analytics capabilities for your Node.js applications.
